ðŸš€ ðŸš€ Evolution of Spark:
âœ… 2013: Apache Spark was donated to Apache, with the addition of ML support, Python APIs, and streaming support.

âœ… 2014: It became a top-level Apache project, with key features like Spark SQL, a graph computation package, and recognition for winning the Daytona Gray Sort 100TB benchmark.

âœ… 2015: Project Tungsten introduced major improvements like the DataFrame API, R APIs, and an ML pipelines API.

âœ… 2016: Spark began operating as a compiler, with features such as Spark ML, the SparkSession API, and whole-stage code generation.

âœ… 2017: Next-generation streaming was introduced with Structured Streaming General Availability (GA), a cost-based optimizer, and Spark's availability in PyPI.

âœ… 2018: Spark introduced vectorized Pandas UDF, barrier execution, a flexible streaming sink, and Spark on Kubernetes.

âœ… 2019: Advanced data sources were added, including Delta Lake, Apache Iceberg, and Apache Hudi.

âœ… 2020: Adaptive execution was introduced, with features like dynamic partition pruning, adaptive query execution, and accelerator-aware scheduling.

âœ… 2021: Project Zen introduced a pandas API, node decommissioning, and RocksDB StateStore support.

âœ… 2022: Spark simplified migration with features like Bloom filter join, improved error messages, and ANSI SQL compliance.

credits : Databricks
